x-dask-tls-secrets: &dask_tls_secrets
  - source: dask_tls_key
    target: ${DASK_TLS_KEY}
  # mode: 444 # not supported by docker stack compose as of 26.0.0
  - source: dask_tls_cert
    target: ${DASK_TLS_CERT}
# mode: 444 # not supported by docker stack compose as of 26.0.0

## common environs

x-common-logging: &common_logging_environments
  LOG_FORMAT_LOCAL_DEV_ENABLED: ${LOG_FORMAT_LOCAL_DEV_ENABLED}
  LOG_FILTER_MAPPING: ${LOG_FILTER_MAPPING}

x-webserver-diagnostics: &webserver_diagnostics_environments
  DIAGNOSTICS_HEALTHCHECK_ENABLED: ${DIAGNOSTICS_HEALTHCHECK_ENABLED}
  DIAGNOSTICS_MAX_AVG_LATENCY: ${DIAGNOSTICS_MAX_AVG_LATENCY}
  DIAGNOSTICS_MAX_TASK_DELAY: ${DIAGNOSTICS_MAX_TASK_DELAY}
  DIAGNOSTICS_SLOW_DURATION_SECS: ${DIAGNOSTICS_SLOW_DURATION_SECS}

x-tracing-open-telemetry: &tracing_open_telemetry_environments
  TRACING_OPENTELEMETRY_COLLECTOR_ENDPOINT: ${TRACING_OPENTELEMETRY_COLLECTOR_ENDPOINT}
  TRACING_OPENTELEMETRY_COLLECTOR_BATCH_SIZE: ${TRACING_OPENTELEMETRY_COLLECTOR_BATCH_SIZE}
  TRACING_OPENTELEMETRY_COLLECTOR_PORT: ${TRACING_OPENTELEMETRY_COLLECTOR_PORT}
  TRACING_OPENTELEMETRY_SAMPLING_PROBABILITY: ${TRACING_OPENTELEMETRY_SAMPLING_PROBABILITY}

## third-party party services
x-postgres-settings: &postgres_settings
  POSTGRES_DB: ${POSTGRES_DB}
  POSTGRES_HOST: ${POSTGRES_HOST}
  POSTGRES_MAXSIZE: ${POSTGRES_MAXSIZE}
  POSTGRES_MINSIZE: ${POSTGRES_MINSIZE}
  POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
  POSTGRES_MAX_POOLSIZE: ${POSTGRES_MAX_POOLSIZE}
  POSTGRES_MAX_OVERFLOW: ${POSTGRES_MAX_OVERFLOW}
  POSTGRES_PORT: ${POSTGRES_PORT}
  POSTGRES_USER: ${POSTGRES_USER}

x-rabbit-settings: &rabbit_settings
  RABBIT_HOST: ${RABBIT_HOST}
  RABBIT_PASSWORD: ${RABBIT_PASSWORD}
  RABBIT_PORT: ${RABBIT_PORT}
  RABBIT_SECURE: ${RABBIT_SECURE}
  RABBIT_USER: ${RABBIT_USER}

x-redis-settings: &redis_settings
  REDIS_HOST: ${REDIS_HOST}
  REDIS_PORT: ${REDIS_PORT}
  REDIS_SECURE: ${REDIS_SECURE}
  REDIS_USER: ${REDIS_USER}
  REDIS_PASSWORD: ${REDIS_PASSWORD}

x-registry-settings: &registry_settings
  REGISTRY_AUTH: ${REGISTRY_AUTH}
  REGISTRY_PATH: ${REGISTRY_PATH}
  REGISTRY_PW: ${REGISTRY_PW}
  REGISTRY_SSL: ${REGISTRY_SSL}
  REGISTRY_URL: ${REGISTRY_URL}
  REGISTRY_USER: ${REGISTRY_USER}

x-s3-settings: &s3_settings
  S3_ACCESS_KEY: ${S3_ACCESS_KEY}
  S3_BUCKET_NAME: ${S3_BUCKET_NAME}
  S3_ENDPOINT: ${S3_ENDPOINT}
  S3_REGION: ${S3_REGION}
  S3_SECRET_KEY: ${S3_SECRET_KEY}

x-smtp-settings: &smtp_settings
  SMTP_HOST: ${SMTP_HOST}
  SMTP_PORT: ${SMTP_PORT}
  SMTP_USERNAME: ${SMTP_USERNAME}
  SMTP_PASSWORD: ${SMTP_PASSWORD}
  SMTP_PROTOCOL: ${SMTP_PROTOCOL}

## simcore stack services

x-catalog-settings: &catalog_settings
  CATALOG_HOST: ${CATALOG_HOST}
  CATALOG_PORT: ${CATALOG_PORT}

x-director-v2-settings: &director_v2_settings
  DIRECTOR_V2_HOST: ${DIRECTOR_V2_HOST}
  DIRECTOR_V2_PORT: ${DIRECTOR_V2_PORT}

x-storage-settings: &storage_settings
  STORAGE_ENDPOINT: ${STORAGE_ENDPOINT}
  STORAGE_HOST: ${STORAGE_HOST}
  STORAGE_PORT: ${STORAGE_PORT}

x-resource-usage-tracker-settings: &resource_usage_tracker_settings
  RESOURCE_USAGE_TRACKER_HOST: ${RESOURCE_USAGE_TRACKER_HOST}
  RESOURCE_USAGE_TRACKER_PORT: ${RESOURCE_USAGE_TRACKER_EXTERNAL_PORT}

x-payments-settings: &payments_settings
  PAYMENTS_HOST: ${PAYMENTS_HOST}
  PAYMENTS_PORT: ${PAYMENTS_PORT}
  PAYMENTS_USERNAME: ${PAYMENTS_USERNAME}
  PAYMENTS_PASSWORD: ${PAYMENTS_PASSWORD}

x-invitations-settings: &invitations_settings
  INVITATIONS_HOST: ${INVITATIONS_HOST}
  INVITATIONS_PORT: ${INVITATIONS_PORT}
  INVITATIONS_USERNAME: ${INVITATIONS_USERNAME}
  INVITATIONS_PASSWORD: ${INVITATIONS_PASSWORD}
  INVITATIONS_SECRET_KEY: ${INVITATIONS_SECRET_KEY}
  INVITATIONS_OSPARC_URL: ${INVITATIONS_OSPARC_URL}

services:
  api-server:
    image: ${DOCKER_REGISTRY:-itisfoundation}/api-server:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    environment: &api_server_environment
      <<:
        - *catalog_settings
        - *director_v2_settings
        - *postgres_settings
        - *rabbit_settings
        - *redis_settings
        - *storage_settings
        - *tracing_open_telemetry_environments

      API_SERVER_DEV_FEATURES_ENABLED: ${API_SERVER_DEV_FEATURES_ENABLED}
      API_SERVER_LOG_FORMAT_LOCAL_DEV_ENABLED: ${LOG_FORMAT_LOCAL_DEV_ENABLED}
      API_SERVER_LOG_FILTER_MAPPING: ${LOG_FILTER_MAPPING}
      API_SERVER_TRACING: ${API_SERVER_TRACING}
      API_SERVER_LOGLEVEL: ${API_SERVER_LOGLEVEL}
      API_SERVER_PROFILING: ${API_SERVER_PROFILING}
      API_SERVER_WORKER_MODE: "false"

      # NOTE: points to wb-api server
      WEBSERVER_HOST: ${WB_API_WEBSERVER_HOST}
      WEBSERVER_PORT: ${WB_API_WEBSERVER_PORT}
      WEBSERVER_RPC_NAMESPACE: ${WB_API_WEBSERVER_HOST}
      WEBSERVER_SESSION_SECRET_KEY: ${WEBSERVER_SESSION_SECRET_KEY}

    deploy:
      labels:
        - io.simcore.zone=${TRAEFIK_SIMCORE_ZONE}
        # gzip compression
        - traefik.http.middlewares.${SWARM_STACK_NAME}_gzip.compress=true
        # ssl header necessary so that socket.io upgrades correctly from polling to websocket mode. the middleware must be attached to the right connection.
        - traefik.enable=true
        - traefik.http.services.${SWARM_STACK_NAME}_api-server.loadbalancer.server.port=8000
        - traefik.http.services.${SWARM_STACK_NAME}_api-server.loadbalancer.healthcheck.path=/
        - traefik.http.services.${SWARM_STACK_NAME}_api-server.loadbalancer.healthcheck.interval=2000ms
        - traefik.http.services.${SWARM_STACK_NAME}_api-server.loadbalancer.healthcheck.timeout=1000ms
        # NOTE: keep in sync with fallback router (rule and entrypoint)
        - traefik.http.routers.${SWARM_STACK_NAME}_api-server.rule=(Path(`/`) || Path(`/v0`) ||  PathPrefix(`/v0/`) || Path(`/api/v0/openapi.json`))
        - traefik.http.routers.${SWARM_STACK_NAME}_api-server.entrypoints=simcore_api
        - traefik.http.routers.${SWARM_STACK_NAME}_api-server.priority=3
        - traefik.http.routers.${SWARM_STACK_NAME}_api-server.middlewares=${SWARM_STACK_NAME}_gzip@swarm,ratelimit-${SWARM_STACK_NAME}_api-server,inflightreq-${SWARM_STACK_NAME}_api-server
    networks: &api_server_networks
      - default

  api-worker:
    image: ${DOCKER_REGISTRY:-itisfoundation}/api-server:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "api-worker-{{.Node.Hostname}}-{{.Task.Slot}}"
    environment:
      <<: *api_server_environment
      API_SERVER_TRACING: "null"
      API_SERVER_WORKER_NAME: "api-worker-{{.Node.Hostname}}-{{.Task.Slot}}-{{.Task.ID}}"
      API_SERVER_WORKER_MODE: "true"
      CELERY_CONCURRENCY: ${API_SERVER_CELERY_CONCURRENCY}
      CELERY_POOL: threads
      CELERY_QUEUES: api_worker_queue
    networks: *api_server_networks

  autoscaling:
    image: ${DOCKER_REGISTRY:-itisfoundation}/autoscaling:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    networks:
      - autoscaling_subnet
    environment:
      <<:
        - *common_logging_environments
        - *rabbit_settings
        - *redis_settings
        - *registry_settings
        - *tracing_open_telemetry_environments

      AUTOSCALING_LOGLEVEL: ${AUTOSCALING_LOGLEVEL}
      AUTOSCALING_POLL_INTERVAL: ${AUTOSCALING_POLL_INTERVAL}
      AUTOSCALING_DRAIN_NODES_WITH_LABELS: ${AUTOSCALING_DRAIN_NODES_WITH_LABELS}
      AUTOSCALING_DOCKER_JOIN_DRAINED: ${AUTOSCALING_DOCKER_JOIN_DRAINED}
      AUTOSCALING_WAIT_FOR_CLOUD_INIT_BEFORE_WARM_BUFFER_ACTIVATION: ${AUTOSCALING_WAIT_FOR_CLOUD_INIT_BEFORE_WARM_BUFFER_ACTIVATION}

      AUTOSCALING_DASK: ${AUTOSCALING_DASK} # comp autoscaling
      DASK_MONITORING_URL: ${DASK_MONITORING_URL}
      DASK_SCHEDULER_AUTH: ${DASK_SCHEDULER_AUTH}

      AUTOSCALING_EC2_ACCESS: ${AUTOSCALING_EC2_ACCESS} # used to enable/disable
      AUTOSCALING_EC2_ACCESS_KEY_ID: ${AUTOSCALING_EC2_ACCESS_KEY_ID}
      AUTOSCALING_EC2_SECRET_ACCESS_KEY: ${AUTOSCALING_EC2_SECRET_ACCESS_KEY}
      AUTOSCALING_EC2_REGION_NAME: ${AUTOSCALING_EC2_REGION_NAME}

      AUTOSCALING_EC2_INSTANCES: ${AUTOSCALING_EC2_INSTANCES} # used to enable/disable
      EC2_INSTANCES_ALLOWED_TYPES: ${EC2_INSTANCES_ALLOWED_TYPES}
      EC2_INSTANCES_ATTACHED_IAM_PROFILE: ${EC2_INSTANCES_ATTACHED_IAM_PROFILE}
      EC2_INSTANCES_COLD_START_DOCKER_IMAGES_PRE_PULLING: ${EC2_INSTANCES_COLD_START_DOCKER_IMAGES_PRE_PULLING}
      EC2_INSTANCES_CUSTOM_TAGS: ${EC2_INSTANCES_CUSTOM_TAGS}
      EC2_INSTANCES_KEY_NAME: ${EC2_INSTANCES_KEY_NAME}
      EC2_INSTANCES_MACHINES_BUFFER: ${EC2_INSTANCES_MACHINES_BUFFER}
      EC2_INSTANCES_MAX_INSTANCES: ${EC2_INSTANCES_MAX_INSTANCES}
      EC2_INSTANCES_MAX_START_TIME: ${EC2_INSTANCES_MAX_START_TIME}
      EC2_INSTANCES_NAME_PREFIX: ${EC2_INSTANCES_NAME_PREFIX}
      EC2_INSTANCES_SECURITY_GROUP_IDS: ${EC2_INSTANCES_SECURITY_GROUP_IDS}
      EC2_INSTANCES_SUBNET_IDS: ${EC2_INSTANCES_SUBNET_IDS}
      EC2_INSTANCES_TIME_BEFORE_DRAINING: ${EC2_INSTANCES_TIME_BEFORE_DRAINING}
      EC2_INSTANCES_TIME_BEFORE_TERMINATION: ${EC2_INSTANCES_TIME_BEFORE_TERMINATION}

      AUTOSCALING_NODES_MONITORING: ${AUTOSCALING_NODES_MONITORING} # dyn autoscaling envvar
      NODES_MONITORING_NODE_LABELS: ${NODES_MONITORING_NODE_LABELS}
      NODES_MONITORING_SERVICE_LABELS: ${NODES_MONITORING_SERVICE_LABELS}
      NODES_MONITORING_NEW_NODES_LABELS: ${NODES_MONITORING_NEW_NODES_LABELS}

      AUTOSCALING_SSM_ACCESS: ${AUTOSCALING_SSM_ACCESS} # used to enable/disable
      SSM_ENDPOINT: ${SSM_ENDPOINT}
      SSM_ACCESS_KEY_ID: ${SSM_ACCESS_KEY_ID}
      SSM_SECRET_ACCESS_KEY: ${SSM_SECRET_ACCESS_KEY}
      SSM_REGION_NAME: ${SSM_REGION_NAME}

      AUTOSCALING_TRACING: ${AUTOSCALING_TRACING}
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    deploy:
      placement:
        constraints:
          - node.role == manager
      resources:
        reservations:
          cpus: "0.5"
          memory: "512M"
        limits:
          cpus: "0.5"
          memory: "512M"

  catalog:
    image: ${DOCKER_REGISTRY:-itisfoundation}/catalog:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "cat-{{.Node.Hostname}}-{{.Task.Slot}}"
    environment:
      <<:
        - *catalog_settings
        - *common_logging_environments
        - *postgres_settings
        - *rabbit_settings
        - *tracing_open_telemetry_environments

      CATALOG_BACKGROUND_TASK_REST_TIME: ${CATALOG_BACKGROUND_TASK_REST_TIME}
      CATALOG_DEV_FEATURES_ENABLED: ${CATALOG_DEV_FEATURES_ENABLED}
      CATALOG_LOGLEVEL: ${CATALOG_LOGLEVEL}
      CATALOG_PROFILING: ${CATALOG_PROFILING}
      CATALOG_SERVICES_DEFAULT_RESOURCES: ${CATALOG_SERVICES_DEFAULT_RESOURCES}
      CATALOG_SERVICES_DEFAULT_SPECIFICATIONS: ${CATALOG_SERVICES_DEFAULT_SPECIFICATIONS}
      CATALOG_TRACING: ${CATALOG_TRACING}
      DIRECTOR_DEFAULT_MAX_MEMORY: ${DIRECTOR_DEFAULT_MAX_MEMORY}
      DIRECTOR_DEFAULT_MAX_NANO_CPUS: ${DIRECTOR_DEFAULT_MAX_NANO_CPUS}
      DIRECTOR_HOST: ${DIRECTOR_HOST:-director}
      DIRECTOR_PORT: ${DIRECTOR_PORT:-8080}

    networks:
      - default

  clusters-keeper:
    image: ${DOCKER_REGISTRY:-itisfoundation}/clusters-keeper:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    networks:
      - default
    environment:
      <<:
        - *common_logging_environments
        - *rabbit_settings
        - *redis_settings
        - *tracing_open_telemetry_environments

      CLUSTERS_KEEPER_COMPUTATIONAL_BACKEND_DOCKER_IMAGE_TAG: ${CLUSTERS_KEEPER_COMPUTATIONAL_BACKEND_DOCKER_IMAGE_TAG}
      CLUSTERS_KEEPER_COMPUTATIONAL_BACKEND_DEFAULT_CLUSTER_AUTH: ${CLUSTERS_KEEPER_COMPUTATIONAL_BACKEND_DEFAULT_CLUSTER_AUTH}
      CLUSTERS_KEEPER_DASK_NPROCS: ${CLUSTERS_KEEPER_DASK_NPROCS}
      CLUSTERS_KEEPER_DASK_NTHREADS: ${CLUSTERS_KEEPER_DASK_NTHREADS}
      CLUSTERS_KEEPER_DASK_NTHREADS_MULTIPLIER: ${CLUSTERS_KEEPER_DASK_NTHREADS_MULTIPLIER}
      CLUSTERS_KEEPER_DASK_WORKER_SATURATION: ${CLUSTERS_KEEPER_DASK_WORKER_SATURATION}
      CLUSTERS_KEEPER_MAX_MISSED_HEARTBEATS_BEFORE_CLUSTER_TERMINATION: ${CLUSTERS_KEEPER_MAX_MISSED_HEARTBEATS_BEFORE_CLUSTER_TERMINATION}
      CLUSTERS_KEEPER_TASK_INTERVAL: ${CLUSTERS_KEEPER_TASK_INTERVAL}
      CLUSTERS_KEEPER_LOGLEVEL: ${CLUSTERS_KEEPER_LOGLEVEL}
      CLUSTERS_KEEPER_EC2_ACCESS: ${CLUSTERS_KEEPER_EC2_ACCESS}
      CLUSTERS_KEEPER_EC2_ACCESS_KEY_ID: ${CLUSTERS_KEEPER_EC2_ACCESS_KEY_ID}
      CLUSTERS_KEEPER_EC2_ENDPOINT: ${CLUSTERS_KEEPER_EC2_ENDPOINT}
      CLUSTERS_KEEPER_EC2_REGION_NAME: ${CLUSTERS_KEEPER_EC2_REGION_NAME}
      CLUSTERS_KEEPER_EC2_SECRET_ACCESS_KEY: ${CLUSTERS_KEEPER_EC2_SECRET_ACCESS_KEY}
      CLUSTERS_KEEPER_SSM_ACCESS: ${CLUSTERS_KEEPER_SSM_ACCESS}
      CLUSTERS_KEEPER_SSM_ACCESS_KEY_ID: ${CLUSTERS_KEEPER_SSM_ACCESS_KEY_ID}
      CLUSTERS_KEEPER_SSM_ENDPOINT: ${CLUSTERS_KEEPER_SSM_ENDPOINT}
      CLUSTERS_KEEPER_SSM_REGION_NAME: ${CLUSTERS_KEEPER_SSM_REGION_NAME}
      CLUSTERS_KEEPER_SSM_SECRET_ACCESS_KEY: ${CLUSTERS_KEEPER_SSM_SECRET_ACCESS_KEY}
      CLUSTERS_KEEPER_EC2_INSTANCES_PREFIX: ${CLUSTERS_KEEPER_EC2_INSTANCES_PREFIX}
      CLUSTERS_KEEPER_PRIMARY_EC2_INSTANCES: ${CLUSTERS_KEEPER_PRIMARY_EC2_INSTANCES}
      PRIMARY_EC2_INSTANCES_ALLOWED_TYPES: ${PRIMARY_EC2_INSTANCES_ALLOWED_TYPES}
      PRIMARY_EC2_INSTANCES_KEY_NAME: ${PRIMARY_EC2_INSTANCES_KEY_NAME}
      PRIMARY_EC2_INSTANCES_MAX_INSTANCES: ${PRIMARY_EC2_INSTANCES_MAX_INSTANCES}
      PRIMARY_EC2_INSTANCES_SECURITY_GROUP_IDS: ${PRIMARY_EC2_INSTANCES_SECURITY_GROUP_IDS}
      PRIMARY_EC2_INSTANCES_SUBNET_IDS: ${PRIMARY_EC2_INSTANCES_SUBNET_IDS}
      PRIMARY_EC2_INSTANCES_CUSTOM_TAGS: ${PRIMARY_EC2_INSTANCES_CUSTOM_TAGS}
      PRIMARY_EC2_INSTANCES_ATTACHED_IAM_PROFILE: ${PRIMARY_EC2_INSTANCES_ATTACHED_IAM_PROFILE}
      PRIMARY_EC2_INSTANCES_SSM_TLS_DASK_CA: ${PRIMARY_EC2_INSTANCES_SSM_TLS_DASK_CA}
      PRIMARY_EC2_INSTANCES_SSM_TLS_DASK_CERT: ${PRIMARY_EC2_INSTANCES_SSM_TLS_DASK_CERT}
      PRIMARY_EC2_INSTANCES_SSM_TLS_DASK_KEY: ${PRIMARY_EC2_INSTANCES_SSM_TLS_DASK_KEY}
      PRIMARY_EC2_INSTANCES_PROMETHEUS_USERNAME: ${PRIMARY_EC2_INSTANCES_PROMETHEUS_USERNAME}
      PRIMARY_EC2_INSTANCES_PROMETHEUS_PASSWORD: ${PRIMARY_EC2_INSTANCES_PROMETHEUS_PASSWORD}
      PRIMARY_EC2_INSTANCES_MAX_START_TIME: ${PRIMARY_EC2_INSTANCES_MAX_START_TIME}
      PRIMARY_EC2_INSTANCES_DOCKER_DEFAULT_ADDRESS_POOL: ${PRIMARY_EC2_INSTANCES_DOCKER_DEFAULT_ADDRESS_POOL}
      PRIMARY_EC2_INSTANCES_RABBIT: ${PRIMARY_EC2_INSTANCES_RABBIT}
      SWARM_STACK_NAME: ${SWARM_STACK_NAME}
      CLUSTERS_KEEPER_WORKERS_EC2_INSTANCES: ${CLUSTERS_KEEPER_WORKERS_EC2_INSTANCES}
      WORKERS_EC2_INSTANCES_ALLOWED_TYPES: ${WORKERS_EC2_INSTANCES_ALLOWED_TYPES}
      WORKERS_EC2_INSTANCES_TIME_BEFORE_DRAINING: ${WORKERS_EC2_INSTANCES_TIME_BEFORE_DRAINING}
      WORKERS_EC2_INSTANCES_TIME_BEFORE_TERMINATION: ${WORKERS_EC2_INSTANCES_TIME_BEFORE_TERMINATION}
      WORKERS_EC2_INSTANCES_KEY_NAME: ${WORKERS_EC2_INSTANCES_KEY_NAME}
      WORKERS_EC2_INSTANCES_MAX_INSTANCES: ${WORKERS_EC2_INSTANCES_MAX_INSTANCES}
      WORKERS_EC2_INSTANCES_MAX_START_TIME: ${WORKERS_EC2_INSTANCES_MAX_START_TIME}
      WORKERS_EC2_INSTANCES_SECURITY_GROUP_IDS: ${WORKERS_EC2_INSTANCES_SECURITY_GROUP_IDS}
      WORKERS_EC2_INSTANCES_SUBNET_IDS: ${WORKERS_EC2_INSTANCES_SUBNET_IDS}
      WORKERS_EC2_INSTANCES_COLD_START_DOCKER_IMAGES_PRE_PULLING: ${WORKERS_EC2_INSTANCES_COLD_START_DOCKER_IMAGES_PRE_PULLING}
      WORKERS_EC2_INSTANCES_CUSTOM_TAGS: ${WORKERS_EC2_INSTANCES_CUSTOM_TAGS}
      CLUSTERS_KEEPER_TRACING: ${CLUSTERS_KEEPER_TRACING}
    secrets: *dask_tls_secrets

  director:
    image: ${DOCKER_REGISTRY:-itisfoundation}/director:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    environment:
      <<:
        - *postgres_settings
        - *registry_settings
        - *tracing_open_telemetry_environments

      DIRECTOR_DEFAULT_MAX_MEMORY: ${DIRECTOR_DEFAULT_MAX_MEMORY}
      DIRECTOR_DEFAULT_MAX_NANO_CPUS: ${DIRECTOR_DEFAULT_MAX_NANO_CPUS}
      DIRECTOR_GENERIC_RESOURCE_PLACEMENT_CONSTRAINTS_SUBSTITUTIONS: ${DIRECTOR_GENERIC_RESOURCE_PLACEMENT_CONSTRAINTS_SUBSTITUTIONS}
      DIRECTOR_LOG_FORMAT_LOCAL_DEV_ENABLED: ${LOG_FORMAT_LOCAL_DEV_ENABLED}
      DIRECTOR_LOGLEVEL: ${DIRECTOR_LOGLEVEL}
      DIRECTOR_MONITORING_ENABLED: ${DIRECTOR_MONITORING_ENABLED}
      DIRECTOR_PUBLISHED_HOST_NAME: ${DIRECTOR_PUBLISHED_HOST_NAME}
      DIRECTOR_REGISTRY_CACHING_TTL: ${DIRECTOR_REGISTRY_CACHING_TTL}
      DIRECTOR_REGISTRY_CACHING: ${DIRECTOR_REGISTRY_CACHING}
      DIRECTOR_SERVICES_CUSTOM_CONSTRAINTS: ${DIRECTOR_SERVICES_CUSTOM_CONSTRAINTS}
      DIRECTOR_TRACING: ${DIRECTOR_TRACING}

      SIMCORE_SERVICES_NETWORK_NAME: interactive_services_subnet
      STORAGE_ENDPOINT: ${STORAGE_ENDPOINT}
      SWARM_STACK_NAME: ${SWARM_STACK_NAME}

      TRAEFIK_SIMCORE_ZONE: ${TRAEFIK_SIMCORE_ZONE}

    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    deploy:
      placement:
        constraints:
          - node.role == manager
    networks:
      - default
      - interactive_services_subnet

  director-v2:
    image: ${DOCKER_REGISTRY:-itisfoundation}/director-v2:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    environment:
      <<:
        - *common_logging_environments
        - *postgres_settings
        - *rabbit_settings
        - *redis_settings
        - *registry_settings
        - *s3_settings
        - *tracing_open_telemetry_environments
      AWS_S3_CLI_S3: ${AWS_S3_CLI_S3}

      CATALOG_HOST: ${CATALOG_HOST}
      CATALOG_PORT: ${CATALOG_PORT}

      COMPUTATIONAL_BACKEND_DEFAULT_CLUSTER_FILE_LINK_TYPE: ${COMPUTATIONAL_BACKEND_DEFAULT_CLUSTER_FILE_LINK_TYPE}
      COMPUTATIONAL_BACKEND_DEFAULT_CLUSTER_URL: ${COMPUTATIONAL_BACKEND_DEFAULT_CLUSTER_URL}
      COMPUTATIONAL_BACKEND_DEFAULT_CLUSTER_AUTH: ${COMPUTATIONAL_BACKEND_DEFAULT_CLUSTER_AUTH}
      COMPUTATIONAL_BACKEND_DEFAULT_FILE_LINK_TYPE: ${COMPUTATIONAL_BACKEND_DEFAULT_FILE_LINK_TYPE}
      COMPUTATIONAL_BACKEND_ON_DEMAND_CLUSTERS_FILE_LINK_TYPE: ${COMPUTATIONAL_BACKEND_ON_DEMAND_CLUSTERS_FILE_LINK_TYPE}

      DIRECTOR_HOST: ${DIRECTOR_HOST}
      DIRECTOR_PORT: ${DIRECTOR_PORT}
      DIRECTOR_V2_GENERIC_RESOURCE_PLACEMENT_CONSTRAINTS_SUBSTITUTIONS: ${DIRECTOR_V2_GENERIC_RESOURCE_PLACEMENT_CONSTRAINTS_SUBSTITUTIONS}

      DIRECTOR_V2_DEV_FEATURES_ENABLED: ${DIRECTOR_V2_DEV_FEATURES_ENABLED}
      DIRECTOR_V2_DYNAMIC_SCHEDULER_CLOSE_SERVICES_VIA_FRONTEND_WHEN_CREDITS_LIMIT_REACHED: ${DIRECTOR_V2_DYNAMIC_SCHEDULER_CLOSE_SERVICES_VIA_FRONTEND_WHEN_CREDITS_LIMIT_REACHED}
      DIRECTOR_V2_SERVICES_CUSTOM_CONSTRAINTS: ${DIRECTOR_V2_SERVICES_CUSTOM_CONSTRAINTS}
      DIRECTOR_V2_PROFILING: ${DIRECTOR_V2_PROFILING}
      DIRECTOR_V2_DYNAMIC_SIDECAR_SLEEP_AFTER_CONTAINER_REMOVAL: ${DIRECTOR_V2_DYNAMIC_SIDECAR_SLEEP_AFTER_CONTAINER_REMOVAL}

      DIRECTOR_V2_DYNAMIC_SCHEDULER_ENABLED: ${DIRECTOR_V2_DYNAMIC_SCHEDULER_ENABLED}

      DYNAMIC_SIDECAR_ENDPOINT_SPECS_MODE_DNSRR_ENABLED: ${DYNAMIC_SIDECAR_ENDPOINT_SPECS_MODE_DNSRR_ENABLED}
      DYNAMIC_SIDECAR_ENABLE_VOLUME_LIMITS: ${DYNAMIC_SIDECAR_ENABLE_VOLUME_LIMITS}
      DYNAMIC_SIDECAR_IMAGE: ${DYNAMIC_SIDECAR_IMAGE}
      DYNAMIC_SIDECAR_LOG_LEVEL: ${DYNAMIC_SIDECAR_LOG_LEVEL}
      DYNAMIC_SIDECAR_PROMETHEUS_MONITORING_NETWORKS: ${DYNAMIC_SIDECAR_PROMETHEUS_MONITORING_NETWORKS}
      DYNAMIC_SIDECAR_PROMETHEUS_SERVICE_LABELS: ${DYNAMIC_SIDECAR_PROMETHEUS_SERVICE_LABELS}
      DYNAMIC_SIDECAR_API_SAVE_RESTORE_STATE_TIMEOUT: ${DYNAMIC_SIDECAR_API_SAVE_RESTORE_STATE_TIMEOUT}

      DIRECTOR_V2_LOGLEVEL: ${DIRECTOR_V2_LOGLEVEL}
      MONITORING_ENABLED: ${MONITORING_ENABLED}

      R_CLONE_OPTION_BUFFER_SIZE: ${R_CLONE_OPTION_BUFFER_SIZE}
      R_CLONE_OPTION_RETRIES: ${R_CLONE_OPTION_RETRIES}
      R_CLONE_OPTION_TRANSFERS: ${R_CLONE_OPTION_TRANSFERS}
      R_CLONE_PROVIDER: ${R_CLONE_PROVIDER}

      EFS_DNS_NAME: ${EFS_DNS_NAME}
      EFS_MOUNTED_PATH: ${EFS_MOUNTED_PATH}
      EFS_PROJECT_SPECIFIC_DATA_DIRECTORY: ${EFS_PROJECT_SPECIFIC_DATA_DIRECTORY}

      DIRECTOR_V2_DOCKER_HUB_REGISTRY: ${DIRECTOR_V2_DOCKER_HUB_REGISTRY}

      RESOURCE_USAGE_TRACKER_HOST: ${RESOURCE_USAGE_TRACKER_HOST}
      RESOURCE_USAGE_TRACKER_PORT: ${RESOURCE_USAGE_TRACKER_EXTERNAL_PORT}

      STORAGE_HOST: ${STORAGE_HOST}
      STORAGE_PORT: ${STORAGE_PORT}
      DIRECTOR_V2_NODE_PORTS_STORAGE_AUTH: ${DIRECTOR_V2_NODE_PORTS_STORAGE_AUTH}

      SIMCORE_SERVICES_NETWORK_NAME: ${SIMCORE_SERVICES_NETWORK_NAME}
      SWARM_STACK_NAME: ${SWARM_STACK_NAME}
      TRAEFIK_SIMCORE_ZONE: ${TRAEFIK_SIMCORE_ZONE}

      DIRECTOR_V2_TRACING: ${DIRECTOR_V2_TRACING}

      # WEBSERVER_AUTH_SETTINGS
      WEBSERVER_HOST: ${WB_AUTH_WEBSERVER_HOST}
      WEBSERVER_PORT: ${WB_AUTH_WEBSERVER_PORT}

    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    deploy:
      placement:
        constraints:
          - node.role == manager
    networks:
      - default
      - interactive_services_subnet
      - computational_services_subnet
    secrets: *dask_tls_secrets

  efs-guardian:
    image: ${DOCKER_REGISTRY:-itisfoundation}/efs-guardian:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    networks:
      - default
    environment:
      <<:
        - *common_logging_environments
        - *postgres_settings
        - *rabbit_settings
        - *redis_settings
        - *tracing_open_telemetry_environments
      SC_USER_ID: ${SC_USER_ID}
      SC_USER_NAME: ${SC_USER_NAME}
      EFS_USER_ID: ${EFS_USER_ID}
      EFS_USER_NAME: ${EFS_USER_NAME}
      EFS_GROUP_ID: ${EFS_GROUP_ID}
      EFS_GROUP_NAME: ${EFS_GROUP_NAME}
      EFS_DNS_NAME: ${EFS_DNS_NAME}
      EFS_DEFAULT_USER_SERVICE_SIZE_BYTES: ${EFS_DEFAULT_USER_SERVICE_SIZE_BYTES}
      EFS_MOUNTED_PATH: ${EFS_MOUNTED_PATH}
      EFS_PROJECT_SPECIFIC_DATA_DIRECTORY: ${EFS_PROJECT_SPECIFIC_DATA_DIRECTORY}
      EFS_GUARDIAN_TRACING: ${EFS_GUARDIAN_TRACING}

  invitations:
    image: ${DOCKER_REGISTRY:-itisfoundation}/invitations:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "inv-{{.Node.Hostname}}-{{.Task.Slot}}"
    networks:
      - default
    environment:
      <<:
        - *common_logging_environments
        - *tracing_open_telemetry_environments
      INVITATIONS_DEFAULT_PRODUCT: ${INVITATIONS_DEFAULT_PRODUCT}
      INVITATIONS_LOGLEVEL: ${INVITATIONS_LOGLEVEL}
      INVITATIONS_OSPARC_URL: ${INVITATIONS_OSPARC_URL}
      INVITATIONS_PASSWORD: ${INVITATIONS_PASSWORD}
      INVITATIONS_SECRET_KEY: ${INVITATIONS_SECRET_KEY}
      INVITATIONS_SWAGGER_API_DOC_ENABLED: ${INVITATIONS_SWAGGER_API_DOC_ENABLED}
      INVITATIONS_TRACING: ${INVITATIONS_TRACING}
      INVITATIONS_USERNAME: ${INVITATIONS_USERNAME}

  payments:
    image: ${DOCKER_REGISTRY:-itisfoundation}/payments:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "pay-{{.Node.Hostname}}-{{.Task.Slot}}"
    networks:
      - default
    environment:
      <<:
        - *common_logging_environments
        - *postgres_settings
        - *rabbit_settings
        - *resource_usage_tracker_settings
        - *smtp_settings
        - *tracing_open_telemetry_environments

      PAYMENTS_ACCESS_TOKEN_EXPIRE_MINUTES: ${PAYMENTS_ACCESS_TOKEN_EXPIRE_MINUTES}
      PAYMENTS_ACCESS_TOKEN_SECRET_KEY: ${PAYMENTS_ACCESS_TOKEN_SECRET_KEY}
      PAYMENTS_AUTORECHARGE_DEFAULT_MONTHLY_LIMIT: ${PAYMENTS_AUTORECHARGE_DEFAULT_MONTHLY_LIMIT}
      PAYMENTS_AUTORECHARGE_DEFAULT_TOP_UP_AMOUNT: ${PAYMENTS_AUTORECHARGE_DEFAULT_TOP_UP_AMOUNT}
      PAYMENTS_AUTORECHARGE_ENABLED: ${PAYMENTS_AUTORECHARGE_ENABLED}
      PAYMENTS_AUTORECHARGE_MIN_BALANCE_IN_CREDITS: ${PAYMENTS_AUTORECHARGE_MIN_BALANCE_IN_CREDITS}
      PAYMENTS_BCC_EMAIL: ${PAYMENTS_BCC_EMAIL}
      PAYMENTS_EMAIL: ${PAYMENTS_EMAIL}
      PAYMENTS_GATEWAY_API_SECRET: ${PAYMENTS_GATEWAY_API_SECRET}
      PAYMENTS_GATEWAY_URL: ${PAYMENTS_GATEWAY_URL}
      PAYMENTS_LOGLEVEL: ${PAYMENTS_LOGLEVEL}
      PAYMENTS_PASSWORD: ${PAYMENTS_PASSWORD}
      PAYMENTS_STRIPE_API_SECRET: ${PAYMENTS_STRIPE_API_SECRET}
      PAYMENTS_STRIPE_URL: ${PAYMENTS_STRIPE_URL}
      PAYMENTS_SWAGGER_API_DOC_ENABLED: ${PAYMENTS_SWAGGER_API_DOC_ENABLED}
      PAYMENTS_TRACING: ${PAYMENTS_TRACING}
      PAYMENTS_USERNAME: ${PAYMENTS_USERNAME}

  resource-usage-tracker:
    image: ${DOCKER_REGISTRY:-itisfoundation}/resource-usage-tracker:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    networks:
      - default
    environment:
      <<:
        - *common_logging_environments
        - *postgres_settings
        - *rabbit_settings
        - *redis_settings
        - *tracing_open_telemetry_environments

      PROMETHEUS_URL: ${RESOURCE_USAGE_TRACKER_PROMETHEUS_URL}
      PROMETHEUS_USERNAME: ${RESOURCE_USAGE_TRACKER_PROMETHEUS_USERNAME}
      PROMETHEUS_PASSWORD: ${RESOURCE_USAGE_TRACKER_PROMETHEUS_PASSWORD}
      RESOURCE_USAGE_TRACKER_LOGLEVEL: ${RESOURCE_USAGE_TRACKER_LOGLEVEL}
      RESOURCE_USAGE_TRACKER_MISSED_HEARTBEAT_CHECK_ENABLED: ${RESOURCE_USAGE_TRACKER_MISSED_HEARTBEAT_CHECK_ENABLED}
      RESOURCE_USAGE_TRACKER_MISSED_HEARTBEAT_INTERVAL_SEC: ${RESOURCE_USAGE_TRACKER_MISSED_HEARTBEAT_INTERVAL_SEC}
      RESOURCE_USAGE_TRACKER_MISSED_HEARTBEAT_COUNTER_FAIL: ${RESOURCE_USAGE_TRACKER_MISSED_HEARTBEAT_COUNTER_FAIL}
      RESOURCE_USAGE_TRACKER_S3: ${RESOURCE_USAGE_TRACKER_S3}
      RESOURCE_USAGE_TRACKER_TRACING: ${RESOURCE_USAGE_TRACKER_TRACING}
      RESOURCE_USAGE_TRACKER_PORT: ${RESOURCE_USAGE_TRACKER_PORT}

  dynamic-schdlr:
    image: ${DOCKER_REGISTRY:-itisfoundation}/dynamic-scheduler:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    networks:
      - default
      - docker_api_subnet
    environment:
      <<:
        - *common_logging_environments
        - *postgres_settings
        - *rabbit_settings
        - *redis_settings
        - *tracing_open_telemetry_environments

      CATALOG_HOST: ${CATALOG_HOST}
      CATALOG_PORT: ${CATALOG_PORT}
      DIRECTOR_V2_HOST: ${DIRECTOR_V2_HOST}
      DIRECTOR_V2_PORT: ${DIRECTOR_V2_PORT}

      DOCKER_API_PROXY_HOST: ${DOCKER_API_PROXY_HOST}
      DOCKER_API_PROXY_PASSWORD: ${DOCKER_API_PROXY_PASSWORD}
      DOCKER_API_PROXY_PORT: ${DOCKER_API_PROXY_PORT}
      DOCKER_API_PROXY_SECURE: ${DOCKER_API_PROXY_SECURE}
      DOCKER_API_PROXY_USER: ${DOCKER_API_PROXY_USER}

      DYNAMIC_SCHEDULER_LOGLEVEL: ${DYNAMIC_SCHEDULER_LOGLEVEL}
      DYNAMIC_SCHEDULER_PROFILING: ${DYNAMIC_SCHEDULER_PROFILING}
      DYNAMIC_SCHEDULER_STOP_SERVICE_TIMEOUT: ${DYNAMIC_SCHEDULER_STOP_SERVICE_TIMEOUT}
      DYNAMIC_SCHEDULER_TRACING: ${DYNAMIC_SCHEDULER_TRACING}
      DYNAMIC_SCHEDULER_UI_STORAGE_SECRET: ${DYNAMIC_SCHEDULER_UI_STORAGE_SECRET}
      DYNAMIC_SCHEDULER_USE_INTERNAL_SCHEDULER: ${DYNAMIC_SCHEDULER_USE_INTERNAL_SCHEDULER}
      DYNAMIC_SIDECAR_API_SAVE_RESTORE_STATE_TIMEOUT: ${DYNAMIC_SIDECAR_API_SAVE_RESTORE_STATE_TIMEOUT}

  docker-api-proxy:
    image: ${DOCKER_REGISTRY:-itisfoundation}/docker-api-proxy:${DOCKER_IMAGE_TAG:-latest}
    init: true
    environment:
      DOCKER_API_PROXY_PASSWORD: ${DOCKER_API_PROXY_PASSWORD}
      DOCKER_API_PROXY_USER: ${DOCKER_API_PROXY_USER}
    deploy:
      placement:
        constraints:
          - node.role == manager
      mode: global
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - docker_api_subnet

  static-webserver:
    image: ${DOCKER_REGISTRY:-itisfoundation}/static-webserver:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    environment:
      SERVER_HOST: 0.0.0.0
      SERVER_PORT: 8000
      SERVER_LOG_LEVEL: error
      SERVER_ROOT: /static-content
    deploy:
      labels:
        - io.simcore.zone=${TRAEFIK_SIMCORE_ZONE}
        - traefik.http.middlewares.${SWARM_STACK_NAME}_gzip.compress=true
        - traefik.enable=true
        - traefik.http.services.${SWARM_STACK_NAME}_static_webserver.loadbalancer.server.port=8000
        - traefik.http.services.${SWARM_STACK_NAME}_static_webserver.loadbalancer.healthcheck.path=/
        - traefik.http.services.${SWARM_STACK_NAME}_static_webserver.loadbalancer.healthcheck.interval=2000ms
        - traefik.http.services.${SWARM_STACK_NAME}_static_webserver.loadbalancer.healthcheck.timeout=1000ms
        - traefik.http.middlewares.${SWARM_STACK_NAME}_static_webserver_retry.retry.attempts=2
        # NOTE: keep in sync with fallback router (rule and entrypoint)
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver.rule=(Path(`/osparc`) || Path(`/s4l`) || Path(`/s4llite`) || Path(`/s4lacad`) || Path(`/s4lengine`) || Path(`/s4ldesktop`) || Path(`/s4ldesktopacad`) || Path(`/tis`) || Path(`/tiplite`) || Path(`/transpiled`) || Path(`/resource`) || PathPrefix(`/osparc/`) || PathPrefix(`/s4l/`) || PathPrefix(`/s4llite/`) || PathPrefix(`/s4lacad/`) || PathPrefix(`/s4lengine/`) || PathPrefix(`/s4ldesktop/`) || PathPrefix(`/s4ldesktopacad/`) || PathPrefix(`/tis/`) || PathPrefix(`/tiplite/`) || PathPrefix(`/transpiled/`) || PathPrefix(`/resource/`))
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver.service=${SWARM_STACK_NAME}_static_webserver
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver.entrypoints=http
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver.priority=6
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver.middlewares=${SWARM_STACK_NAME}_gzip@swarm,${SWARM_STACK_NAME}_static_webserver_retry
        # catchall for legacy services (this happens if a backend disappears and a frontend tries to reconnect, the right return value is a 503)
        - traefik.http.routers.${SWARM_STACK_NAME}_legacy_services_catchall.service=${SWARM_STACK_NAME}_legacy_services_catchall
        - traefik.http.routers.${SWARM_STACK_NAME}_legacy_services_catchall.priority=3
        - traefik.http.routers.${SWARM_STACK_NAME}_legacy_services_catchall.entrypoints=http
        - traefik.http.routers.${SWARM_STACK_NAME}_legacy_services_catchall.rule=PathRegexp(`^/x/(?P<node_uuid>\b[0-9a-f]{8}\b-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-\b[0-9a-f]{12}\b)[\/]?`)
        # this tricks traefik into a 502 (bad gateway) since the service does not exist on this port
        - traefik.http.services.${SWARM_STACK_NAME}_legacy_services_catchall.loadbalancer.server.port=0
        # this tricks traefik into returning a 503 (service unavailable) since the healthcheck will always return false
        - traefik.http.services.${SWARM_STACK_NAME}_legacy_services_catchall.loadbalancer.healthcheck.path=/some/invalid/path/to/generate/a/503
        - traefik.http.services.${SWARM_STACK_NAME}_legacy_services_catchall.loadbalancer.healthcheck.interval=500s
        - traefik.http.services.${SWARM_STACK_NAME}_legacy_services_catchall.loadbalancer.healthcheck.timeout=1ms
        # see [#2718](https://github.com/ITISFoundation/osparc-simcore/issues/2718)
        # catchall for dynamic-sidecar powered-services (this happens if a backend disappears and a frontend tries to reconnect, the right return value is a 503)
        - traefik.http.routers.${SWARM_STACK_NAME}_modern_services_catchall.service=${SWARM_STACK_NAME}_modern_services_catchall
        # the priority is a bit higher than webserver, the webserver is the fallback to everything and has prio 2
        - traefik.http.routers.${SWARM_STACK_NAME}_modern_services_catchall.priority=9
        - traefik.http.routers.${SWARM_STACK_NAME}_modern_services_catchall.entrypoints=http
        # in theory the pattern should be uuid.services.OSPARC_DOMAIN, but anything could go through.. so let's catch everything
        - traefik.http.routers.${SWARM_STACK_NAME}_modern_services_catchall.rule=HostRegexp(`(?P<node_uuid>\b[0-9a-f]{8}\b-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-\b[0-9a-f]{12}\b)\.services\.(?P<host>.+)`)
        # this tricks traefik into a 502 (bad gateway) since the service does not exist on this port
        - traefik.http.services.${SWARM_STACK_NAME}_modern_services_catchall.loadbalancer.server.port=0
        # this tricks traefik into returning a 503 (service unavailable) since the healthcheck will always return false
        - traefik.http.services.${SWARM_STACK_NAME}_modern_services_catchall.loadbalancer.healthcheck.path=/some/invalid/path/to/generate/a/503
        - traefik.http.services.${SWARM_STACK_NAME}_modern_services_catchall.loadbalancer.healthcheck.interval=500s
        - traefik.http.services.${SWARM_STACK_NAME}_modern_services_catchall.loadbalancer.healthcheck.timeout=1ms
    networks:
      - default

  webserver:
    image: ${DOCKER_REGISTRY:-itisfoundation}/webserver:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "wb-{{.Node.Hostname}}-{{.Task.Slot}}" # the hostname is used in conjonction with other services and must be unique see https://github.com/ITISFoundation/osparc-simcore/pull/5931
    environment: &webserver_environment
      <<:
        - *catalog_settings
        - *director_v2_settings
        - *invitations_settings
        - *payments_settings
        - *postgres_settings
        - *rabbit_settings
        - *redis_settings
        - *resource_usage_tracker_settings
        - *smtp_settings
        - *storage_settings
        - *tracing_open_telemetry_environments
        - *webserver_diagnostics_environments

      AIODEBUG_SLOW_DURATION_SECS: ${AIODEBUG_SLOW_DURATION_SECS}

      SWARM_STACK_NAME: ${SWARM_STACK_NAME}

      WEBSERVER_DEV_FEATURES_ENABLED: ${WEBSERVER_DEV_FEATURES_ENABLED}
      WEBSERVER_REALTIME_COLLABORATION: ${WEBSERVER_REALTIME_COLLABORATION}
      WEBSERVER_LOGLEVEL: ${WEBSERVER_LOGLEVEL}
      WEBSERVER_PROFILING: ${WEBSERVER_PROFILING}

      WEBSERVER_LOG_FORMAT_LOCAL_DEV_ENABLED: ${LOG_FORMAT_LOCAL_DEV_ENABLED}
      WEBSERVER_LOG_FILTER_MAPPING: ${LOG_FILTER_MAPPING}

      # NOTE: keep in sync with the prefix form the hostname
      LONG_RUNNING_TASKS_NAMESPACE_SUFFIX: wb

      # WEBSERVER_SERVER_HOST
      WEBSERVER_HOST: ${WEBSERVER_HOST}
      WEBSERVER_PORT: ${WEBSERVER_PORT}
      WEBSERVER_RPC_NAMESPACE: webserver

      # WEBSERVER / -> index.html
      WEBSERVER_FRONTEND: ${WEBSERVER_FRONTEND}

      # WEBSERVER_ACTIVITY
      WEBSERVER_ACTIVITY: ${WEBSERVER_ACTIVITY}
      PROMETHEUS_API_VERSION: ${WEBSERVER_PROMETHEUS_API_VERSION} # seems to be not used
      PROMETHEUS_URL: ${WEBSERVER_PROMETHEUS_URL}

      WEBSERVER_CATALOG: ${WEBSERVER_CATALOG}
      WEBSERVER_CHATBOT: ${WEBSERVER_CHATBOT}
      WEBSERVER_CONVERSATIONS: "true"

      # WEBSERVER_CREDIT_COMPUTATION
      WEBSERVER_CREDIT_COMPUTATION_ENABLED: ${WEBSERVER_CREDIT_COMPUTATION_ENABLED}

      # WEBSERVER_DIAGNOSTICS
      WEBSERVER_DIAGNOSTICS: ${WEBSERVER_DIAGNOSTICS}

      # WEBSERVER_DIRECTOR_V2

      # WEBSERVER_EMAIL
      WEBSERVER_EMAIL: ${WEBSERVER_EMAIL}

      WEBSERVER_EXPORTER: ${WEBSERVER_EXPORTER}

      # WEBSERVER_GARBAGE_COLLECTOR
      WEBSERVER_GARBAGE_COLLECTOR: ${WEBSERVER_GARBAGE_COLLECTOR}

      # WEBSERVER_INVITATIONS
      INVITATIONS_LOGLEVEL: ${INVITATIONS_LOGLEVEL}
      INVITATIONS_OSPARC_URL: ${INVITATIONS_OSPARC_URL}

      WEBSERVER_LICENSES: ${WEBSERVER_LICENSES}
      WEBSERVER_FOGBUGZ: ${WEBSERVER_FOGBUGZ}
      LICENSES_ITIS_VIP_SYNCER_ENABLED: ${LICENSES_ITIS_VIP_SYNCER_ENABLED}
      LICENSES_ITIS_VIP_SYNCER_PERIODICITY: ${LICENSES_ITIS_VIP_SYNCER_PERIODICITY}
      LICENSES_ITIS_VIP_API_URL: ${LICENSES_ITIS_VIP_API_URL}
      LICENSES_ITIS_VIP_CATEGORIES: ${LICENSES_ITIS_VIP_CATEGORIES}
      LICENSES_SPEAG_PHANTOMS_API_URL: ${LICENSES_SPEAG_PHANTOMS_API_URL}
      LICENSES_SPEAG_PHANTOMS_CATEGORIES: ${LICENSES_SPEAG_PHANTOMS_CATEGORIES}

      WEBSERVER_LOGIN: ${WEBSERVER_LOGIN}
      LOGIN_ACCOUNT_DELETION_RETENTION_DAYS: ${LOGIN_ACCOUNT_DELETION_RETENTION_DAYS}
      LOGIN_REGISTRATION_CONFIRMATION_REQUIRED: ${LOGIN_REGISTRATION_CONFIRMATION_REQUIRED}
      LOGIN_REGISTRATION_INVITATION_REQUIRED: ${LOGIN_REGISTRATION_INVITATION_REQUIRED}
      LOGIN_2FA_REQUIRED: ${LOGIN_2FA_REQUIRED}
      LOGIN_2FA_CODE_EXPIRATION_SEC: ${LOGIN_2FA_CODE_EXPIRATION_SEC}
      TWILIO_ACCOUNT_SID: ${TWILIO_ACCOUNT_SID}
      TWILIO_AUTH_TOKEN: ${TWILIO_AUTH_TOKEN}
      TWILIO_COUNTRY_CODES_W_ALPHANUMERIC_SID_SUPPORT: ${TWILIO_COUNTRY_CODES_W_ALPHANUMERIC_SID_SUPPORT}

      WEBSERVER_PAYMENTS: ${WEBSERVER_PAYMENTS}
      PAYMENTS_AUTORECHARGE_DEFAULT_MONTHLY_LIMIT: ${PAYMENTS_AUTORECHARGE_DEFAULT_MONTHLY_LIMIT}
      PAYMENTS_AUTORECHARGE_DEFAULT_TOP_UP_AMOUNT: ${PAYMENTS_AUTORECHARGE_DEFAULT_TOP_UP_AMOUNT}
      PAYMENTS_AUTORECHARGE_MIN_BALANCE_IN_CREDITS: ${PAYMENTS_AUTORECHARGE_MIN_BALANCE_IN_CREDITS}
      PAYMENTS_FAKE_COMPLETION_DELAY_SEC: ${PAYMENTS_FAKE_COMPLETION_DELAY_SEC}
      PAYMENTS_FAKE_COMPLETION: ${PAYMENTS_FAKE_COMPLETION}
      PAYMENTS_FAKE_GATEWAY_URL: ${PAYMENTS_GATEWAY_URL}

      # WEBSERVER_REST
      REST_SWAGGER_API_DOC_ENABLED: ${REST_SWAGGER_API_DOC_ENABLED}

      # WEBSERVER_RESOURCE_MANAGER
      RESOURCE_MANAGER_RESOURCE_TTL_S: ${RESOURCE_MANAGER_RESOURCE_TTL_S}

      # WEBSERVER_RESOURCE_USAGE_TRACKER

      # WEBSERVER_SCICRUNCH
      WEBSERVER_SCICRUNCH: ${WEBSERVER_SCICRUNCH}
      SCICRUNCH_API_BASE_URL: ${SCICRUNCH_API_BASE_URL}
      SCICRUNCH_API_KEY: ${SCICRUNCH_API_KEY}

      # WEBSERVER_SESSION
      SESSION_SECRET_KEY: ${WEBSERVER_SESSION_SECRET_KEY}
      SESSION_COOKIE_MAX_AGE: ${SESSION_COOKIE_MAX_AGE}
      SESSION_COOKIE_SAMESITE: ${SESSION_COOKIE_SAMESITE}
      SESSION_COOKIE_SECURE: ${SESSION_COOKIE_SECURE}
      SESSION_COOKIE_HTTPONLY: ${SESSION_COOKIE_HTTPONLY}

      WEBSERVER_STATICWEB: ${WEBSERVER_STATICWEB}

      SIMCORE_VCS_RELEASE_TAG: ${SIMCORE_VCS_RELEASE_TAG}

      # WEBSERVER_STORAGE

      # WEBSERVER_STUDIES_DISPATCHER
      WEBSERVER_STUDIES_DISPATCHER: ${WEBSERVER_STUDIES_DISPATCHER}
      STUDIES_ACCESS_ANONYMOUS_ALLOWED: ${STUDIES_ACCESS_ANONYMOUS_ALLOWED}
      STUDIES_DEFAULT_SERVICE_THUMBNAIL: ${STUDIES_DEFAULT_SERVICE_THUMBNAIL}

      WEBSERVER_TRACING: ${WEBSERVER_TRACING}

      # WEBSERVER_PROJECTS
      WEBSERVER_PROJECTS: ${WEBSERVER_PROJECTS}
      PROJECTS_INACTIVITY_INTERVAL: ${PROJECTS_INACTIVITY_INTERVAL}
      PROJECTS_MAX_COPY_SIZE_BYTES: ${PROJECTS_MAX_COPY_SIZE_BYTES}
      PROJECTS_MAX_NUM_RUNNING_DYNAMIC_NODES: ${PROJECTS_MAX_NUM_RUNNING_DYNAMIC_NODES}

      # WEBSERVER_TRASH
      TRASH_RETENTION_DAYS: ${TRASH_RETENTION_DAYS}

      # ARBITRARY ENV VARS

      # see [https://docs.gunicorn.org/en/stable/settings.html#timeout],
      # since we have the docker healthcheck already, this should be ok
      GUNICORN_CMD_ARGS: ${WEBSERVER_GUNICORN_CMD_ARGS}
      WEBSERVER_DB_LISTENER: ${WEBSERVER_DB_LISTENER}
      WEBSERVER_ANNOUNCEMENTS: ${WEBSERVER_ANNOUNCEMENTS}
      WEBSERVER_NOTIFICATIONS: ${WEBSERVER_NOTIFICATIONS}
      WEBSERVER_FUNCTIONS: ${WEBSERVER_FUNCTIONS} # neede for front-end
      WEBSERVER_GROUPS: ${WEBSERVER_GROUPS}
      WEBSERVER_PRODUCTS: ${WEBSERVER_PRODUCTS}
      WEBSERVER_PUBLICATIONS: ${WEBSERVER_PUBLICATIONS}
      WEBSERVER_SOCKETIO: ${WEBSERVER_SOCKETIO}
      WEBSERVER_TAGS: ${WEBSERVER_TAGS}
      WEBSERVER_USERS: ${WEBSERVER_USERS}
      WEBSERVER_FOLDERS: ${WEBSERVER_FOLDERS}

    deploy:
      # NOTE: having 2 replicas is necessary to detect early on if in-process tasks are mistakenly added to the webserver
      # in case this cannot be done otherwise, the sticky rule below will need to be adapted
      replicas: 2
      labels:
        - io.simcore.zone=${TRAEFIK_SIMCORE_ZONE}
        # gzip compression
        - traefik.http.middlewares.${SWARM_STACK_NAME}_gzip.compress=true
        # ssl header necessary so that socket.io upgrades correctly from polling to websocket mode. the middleware must be attached to the right connection.
        - traefik.http.middlewares.${SWARM_STACK_NAME_NO_HYPHEN}_sslheader.headers.customrequestheaders.X-Forwarded-Proto=http
        - traefik.enable=true
        - traefik.http.services.${SWARM_STACK_NAME}_webserver.loadbalancer.server.port=8080
        - traefik.http.services.${SWARM_STACK_NAME}_webserver.loadbalancer.healthcheck.path=/v0/
        - traefik.http.services.${SWARM_STACK_NAME}_webserver.loadbalancer.healthcheck.interval=2000ms
        - traefik.http.services.${SWARM_STACK_NAME}_webserver.loadbalancer.healthcheck.timeout=1000ms
        # NOTE: stickyness must remain only for specific endpoints, see https://github.com/ITISFoundation/osparc-simcore/pull/4180
        - traefik.http.middlewares.${SWARM_STACK_NAME}_webserver_retry.retry.attempts=2
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver.service=${SWARM_STACK_NAME}_webserver
        # NOTE: keep in sync with fallback router (rule and entrypoint)
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver.rule=(Path(`/`) || Path(`/v0`) || Path(`/socket.io/`) || Path(`/static-frontend-data.json`) || PathRegexp(`^/study/(?P<study_uuid>\b[0-9a-f]{8}\b-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-\b[0-9a-f]{12}\b)`) || Path(`/view`) || Path(`/#/view`) || Path(`/#/error`) || PathPrefix(`/v0/`))
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver.entrypoints=http
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver.priority=6
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver.middlewares=${SWARM_STACK_NAME}_gzip@swarm, ${SWARM_STACK_NAME_NO_HYPHEN}_sslheader@swarm, ${SWARM_STACK_NAME}_webserver_retry
        # Create a dedicated sticky service for specific endpoints
        - traefik.http.services.${SWARM_STACK_NAME}_webserver_sticky.loadbalancer.server.port=8080
        - traefik.http.services.${SWARM_STACK_NAME}_webserver_sticky.loadbalancer.healthcheck.path=/v0/
        - traefik.http.services.${SWARM_STACK_NAME}_webserver_sticky.loadbalancer.healthcheck.interval=2000ms
        - traefik.http.services.${SWARM_STACK_NAME}_webserver_sticky.loadbalancer.healthcheck.timeout=1000ms
        - traefik.http.services.${SWARM_STACK_NAME}_webserver_sticky.loadbalancer.sticky.cookie=true
        - traefik.http.services.${SWARM_STACK_NAME}_webserver_sticky.loadbalancer.sticky.cookie.secure=true
        - traefik.http.services.${SWARM_STACK_NAME}_webserver_sticky.loadbalancer.sticky.cookie.httpOnly=true
        - traefik.http.services.${SWARM_STACK_NAME}_webserver_sticky.loadbalancer.sticky.cookie.sameSite=lax
        # Single consolidated router for all sticky endpoints
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_sticky.rule=Path(`/v0/projects`) ||
          Path(`/v0/projects:clone`) ||
          PathRegexp(`^/v0/projects/[0-9a-fA-F-]+/nodes/[0-9a-fA-F-]+:stop`) ||
          PathRegexp(`^/v0/projects/[0-9a-fA-F-]+/nodes/[0-9a-fA-F-]+:open`) ||
          PathRegexp(`^/v0/projects/[0-9a-fA-F-]+/nodes/[0-9a-fA-F-]+:close`) ||
          PathRegexp(`^/v0/storage/locations/[0-9]+/paths/.+:size`) ||
          PathRegexp(`^/v0/storage/locations/[0-9]+/-/paths:batchDelete`) ||
          PathRegexp(`^/v0/storage/locations/[0-9]+:export-data`) ||
          PathRegexp(`^/v0/tasks-legacy/.+`)
        # NOTE: the sticky router must have a higher priority than the webserver router but below dy-proxies
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_sticky.priority=8
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_sticky.entrypoints=http
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_sticky.service=${SWARM_STACK_NAME}_webserver_sticky
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_sticky.middlewares=${SWARM_STACK_NAME}_gzip@swarm, ${SWARM_STACK_NAME_NO_HYPHEN}_sslheader@swarm, ${SWARM_STACK_NAME}_webserver_retry
    networks: &webserver_networks
      - default
      - interactive_services_subnet

  wb-api-server:
    image: ${DOCKER_REGISTRY:-itisfoundation}/webserver:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "api-{{.Node.Hostname}}-{{.Task.Slot}}" # the hostname is used in conjonction with other services and must be unique see https://github.com/ITISFoundation/osparc-simcore/pull/5931
    environment:
      <<: *webserver_environment
      WEBSERVER_FUNCTIONS: ${WEBSERVER_FUNCTIONS} # needed for api-server
      WEBSERVER_HOST: ${WB_API_WEBSERVER_HOST}
      WEBSERVER_PORT: ${WB_API_WEBSERVER_PORT}
      WEBSERVER_RPC_NAMESPACE: ${WB_API_WEBSERVER_HOST}
      WEBSERVER_STATICWEB: "null"
      WEBSERVER_CONVERSATIONS: "false" # override *webserver_environment
      WEBSERVER_CHATBOT: "null" # override *webserver_environment
      WEBSERVER_FOGBUGZ: "null" # override *webserver_environment

      # NOTE: keep in sync with the prefix form the hostname
      LONG_RUNNING_TASKS_NAMESPACE_SUFFIX: api

    networks: *webserver_networks

  wb-db-event-listener:
    image: ${DOCKER_REGISTRY:-itisfoundation}/webserver:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "db-{{.Node.Hostname}}-{{.Task.Slot}}" # the hostname is used in conjonction with other services and must be unique see https://github.com/ITISFoundation/osparc-simcore/pull/5931
    environment:
      <<:
        - *common_logging_environments
        - *postgres_settings
        - *rabbit_settings
        - *redis_settings

      WEBSERVER_LOGLEVEL: ${WB_DB_EL_LOGLEVEL}

      # NOTE: keep in sync with the prefix form the hostname
      LONG_RUNNING_TASKS_NAMESPACE_SUFFIX: db

      WEBSERVER_HOST: ${WEBSERVER_HOST}
      WEBSERVER_PORT: ${WEBSERVER_PORT}
      WEBSERVER_RPC_NAMESPACE: webserver

      DIRECTOR_V2_HOST: ${DIRECTOR_V2_HOST}
      DIRECTOR_V2_PORT: ${DIRECTOR_V2_PORT}

      REST_SWAGGER_API_DOC_ENABLED: ${WB_DB_EL_REST_SWAGGER_API_DOC_ENABLED}

      # WEBSERVER_RESOURCE_USAGE_TRACKER
      RESOURCE_USAGE_TRACKER_HOST: ${RESOURCE_USAGE_TRACKER_HOST}
      RESOURCE_USAGE_TRACKER_PORT: ${RESOURCE_USAGE_TRACKER_EXTERNAL_PORT}

      GUNICORN_CMD_ARGS: ${WEBSERVER_GUNICORN_CMD_ARGS}
      SWARM_STACK_NAME: ${SWARM_STACK_NAME}
      SESSION_SECRET_KEY: ${WEBSERVER_SESSION_SECRET_KEY}
      WEBSERVER_ACTIVITY: ${WB_DB_EL_ACTIVITY}
      WEBSERVER_ANNOUNCEMENTS: ${WB_DB_EL_ANNOUNCEMENTS}
      WEBSERVER_CATALOG: ${WB_DB_EL_CATALOG}
      WEBSERVER_CHATBOT: "null"
      WEBSERVER_CONVERSATIONS: "false"
      WEBSERVER_CELERY: "null"
      WEBSERVER_DB_LISTENER: ${WB_DB_EL_DB_LISTENER}
      WEBSERVER_DIAGNOSTICS: ${WB_DB_EL_DIAGNOSTICS}
      WEBSERVER_EMAIL: ${WB_DB_EL_EMAIL}
      WEBSERVER_EXPORTER: ${WB_DB_EL_EXPORTER}
      WEBSERVER_FOLDERS: ${WB_DB_EL_FOLDERS}
      WEBSERVER_FRONTEND: ${WB_DB_EL_FRONTEND}
      WEBSERVER_FUNCTIONS: 0
      WEBSERVER_GARBAGE_COLLECTOR: ${WB_DB_EL_GARBAGE_COLLECTOR}
      WEBSERVER_GROUPS: ${WB_DB_EL_GROUPS}
      WEBSERVER_INVITATIONS: ${WB_DB_EL_INVITATIONS}
      WEBSERVER_LICENSES: "null"
      WEBSERVER_FOGBUGZ: "null"
      WEBSERVER_LOGIN: ${WB_DB_EL_LOGIN}
      WEBSERVER_PAYMENTS: ${WB_DB_EL_PAYMENTS}
      WEBSERVER_NOTIFICATIONS: ${WB_DB_EL_NOTIFICATIONS}
      WEBSERVER_PRODUCTS: ${WB_DB_EL_PRODUCTS}
      WEBSERVER_PROJECTS: ${WB_DB_EL_PROJECTS}
      WEBSERVER_PUBLICATIONS: ${WB_DB_EL_PUBLICATIONS}
      WEBSERVER_SCICRUNCH: ${WB_DB_EL_SCICRUNCH}
      WEBSERVER_SOCKETIO: ${WB_DB_EL_SOCKETIO}
      WEBSERVER_STATICWEB: ${WB_DB_EL_STATICWEB}
      WEBSERVER_STORAGE: ${WB_DB_EL_STORAGE}
      WEBSERVER_STUDIES_DISPATCHER: ${WB_DB_EL_STUDIES_DISPATCHER}
      WEBSERVER_TAGS: ${WB_DB_EL_TAGS}
      WEBSERVER_TRACING: ${WB_DB_EL_TRACING}
      WEBSERVER_USERS: ${WB_DB_EL_USERS}
      WEBSERVER_WALLETS: ${WB_DB_EL_WALLETS}

      RESOURCE_MANAGER_RESOURCE_TTL_S: ${RESOURCE_MANAGER_RESOURCE_TTL_S}

    deploy:
      # NOTE: https://github.com/ITISFoundation/osparc-simcore/pull/4286
      # NOTE: this MUSTN'T change, or weird things might happen
      # this will stay until all legacy dynamic services are gone.
      replicas: 1
    networks:
      - default

  wb-garbage-collector:
    image: ${DOCKER_REGISTRY:-itisfoundation}/webserver:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "gc-{{.Node.Hostname}}-{{.Task.Slot}}" # the hostname is used in conjonction with other services and must be unique see https://github.com/ITISFoundation/osparc-simcore/pull/5931
    environment:
      <<:
        - *common_logging_environments
        - *director_v2_settings
        - *postgres_settings
        - *rabbit_settings
        - *redis_settings
        - *storage_settings
        - *resource_usage_tracker_settings
        - *tracing_open_telemetry_environments

      # WEBSERVER_DIRECTOR_V2

      GUNICORN_CMD_ARGS: ${WEBSERVER_GUNICORN_CMD_ARGS}

      # NOTE: keep in sync with the prefix form the hostname
      LONG_RUNNING_TASKS_NAMESPACE_SUFFIX: gc

      # WEBSERVER_RESOURCE_MANAGER
      RESOURCE_MANAGER_RESOURCE_TTL_S: ${WB_GC_RESOURCE_MANAGER_RESOURCE_TTL_S}

      # WEBSERVER_RESOURCE_USAGE_TRACKER

      REST_SWAGGER_API_DOC_ENABLED: ${WB_GC_REST_SWAGGER_API_DOC_ENABLED}

      # WEBSERVER_SESSION
      SESSION_SECRET_KEY: ${WEBSERVER_SESSION_SECRET_KEY}

      # WEBSERVER_STORAGE

      SWARM_STACK_NAME: ${SWARM_STACK_NAME}

      # WEBSERVER_TRASH
      TRASH_RETENTION_DAYS: ${TRASH_RETENTION_DAYS}

      WEBSERVER_ACTIVITY: ${WB_GC_ACTIVITY}
      WEBSERVER_ANNOUNCEMENTS: ${WB_GC_ANNOUNCEMENTS}
      WEBSERVER_CATALOG: ${WB_GC_CATALOG}
      WEBSERVER_CHATBOT: "null"
      WEBSERVER_CONVERSATIONS: "false"
      WEBSERVER_CELERY: "null"
      WEBSERVER_DB_LISTENER: ${WB_GC_DB_LISTENER}
      WEBSERVER_DIAGNOSTICS: ${WB_GC_DIAGNOSTICS}
      WEBSERVER_EMAIL: ${WB_GC_EMAIL}
      WEBSERVER_EXPORTER: ${WB_GC_EXPORTER}
      WEBSERVER_FOGBUGZ: "null"
      WEBSERVER_FOLDERS: ${WB_GC_FOLDERS}
      WEBSERVER_FRONTEND: ${WB_GC_FRONTEND}
      WEBSERVER_FUNCTIONS: 0
      WEBSERVER_GARBAGE_COLLECTOR: ${WB_GC_GARBAGE_COLLECTOR}
      WEBSERVER_GROUPS: ${WB_GC_GROUPS}
      WEBSERVER_HOST: ${WEBSERVER_HOST}
      WEBSERVER_INVITATIONS: ${WB_GC_INVITATIONS}
      WEBSERVER_LICENSES: "null"
      WEBSERVER_LOGIN: ${WB_GC_LOGIN}
      WEBSERVER_LOGLEVEL: ${WB_GC_LOGLEVEL}
      WEBSERVER_NOTIFICATIONS: ${WB_GC_NOTIFICATIONS}
      WEBSERVER_PAYMENTS: ${WB_GC_PAYMENTS}
      WEBSERVER_PORT: ${WEBSERVER_PORT}
      WEBSERVER_PRODUCTS: ${WB_GC_PRODUCTS}
      WEBSERVER_PROJECTS: ${WB_GC_PROJECTS}
      WEBSERVER_PUBLICATIONS: ${WB_GC_PUBLICATIONS}
      WEBSERVER_RPC_NAMESPACE: webserver
      WEBSERVER_SCICRUNCH: ${WB_GC_SCICRUNCH}
      WEBSERVER_SOCKETIO: ${WB_GC_SOCKETIO}
      WEBSERVER_STATICWEB: ${WB_GC_STATICWEB}
      WEBSERVER_STUDIES_DISPATCHER: ${WB_GC_STUDIES_DISPATCHER}
      WEBSERVER_TAGS: ${WB_GC_TAGS}
      WEBSERVER_TRACING: ${WB_GC_TRACING}
      WEBSERVER_USERS: ${WB_GC_USERS}
      WEBSERVER_WALLETS: ${WB_GC_WALLETS}

    networks:
      - default
      - interactive_services_subnet

  wb-auth:
    image: ${DOCKER_REGISTRY:-itisfoundation}/webserver:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "auth-{{.Node.Hostname}}-{{.Task.Slot}}" # the hostname is used in conjonction with other services and must be unique see https://github.com/ITISFoundation/osparc-simcore/pull/5931
    environment:
      <<:
        - *postgres_settings
        - *tracing_open_telemetry_environments
        - *webserver_diagnostics_environments

      APP_NAME: "simcore_service_wb_auth"
      WEBSERVER_APP_FACTORY_NAME: WEBSERVER_AUTHZ_APP_FACTORY
      WEBSERVER_LOGLEVEL: ${WB_AUTH_LOGLEVEL}

      # NOTE: keep in sync with the prefix form the hostname
      LONG_RUNNING_TASKS_NAMESPACE_SUFFIX: auth

      GUNICORN_CMD_ARGS: ${WEBSERVER_GUNICORN_CMD_ARGS}

      # WEBSERVER_DIAGNOSTICS
      WEBSERVER_DIAGNOSTICS: ${WB_AUTH_DIAGNOSTICS}

      # WEBSERVER_REST
      REST_SWAGGER_API_DOC_ENABLED: 0

      # WEBSERVER_SERVER_HOST
      WEBSERVER_HOST: ${WB_AUTH_WEBSERVER_HOST}
      WEBSERVER_PORT: ${WB_AUTH_WEBSERVER_PORT}

      # WEBSERVER_SESSION Enabled
      SESSION_SECRET_KEY: ${WEBSERVER_SESSION_SECRET_KEY}
      SESSION_COOKIE_MAX_AGE: ${SESSION_COOKIE_MAX_AGE}
      SESSION_COOKIE_SAMESITE: ${SESSION_COOKIE_SAMESITE}
      SESSION_COOKIE_SECURE: ${SESSION_COOKIE_SECURE}
      SESSION_COOKIE_HTTPONLY: ${SESSION_COOKIE_HTTPONLY}

      WEBSERVER_ACTIVITY: "null"
      WEBSERVER_ANNOUNCEMENTS: 0
      WEBSERVER_CATALOG: "null"
      WEBSERVER_CHATBOT: "null"
      WEBSERVER_CONVERSATIONS: "false"
      WEBSERVER_CELERY: "null"
      WEBSERVER_DB_LISTENER: 0
      WEBSERVER_DIRECTOR_V2: "null"
      WEBSERVER_EMAIL: "null"
      WEBSERVER_EXPORTER: "null"
      WEBSERVER_FOGBUGZ: "null"
      WEBSERVER_FOLDERS: 0
      WEBSERVER_FRONTEND: "null"
      WEBSERVER_FUNCTIONS: 0
      WEBSERVER_GARBAGE_COLLECTOR: "null"
      WEBSERVER_GROUPS: 0
      WEBSERVER_INVITATIONS: "null"
      WEBSERVER_LICENSES: "null"
      WEBSERVER_LOGIN: "null"
      WEBSERVER_NOTIFICATIONS: 0
      WEBSERVER_PAYMENTS: "null"
      WEBSERVER_PRODUCTS: 1
      WEBSERVER_PROFILING: ${WB_AUTH_PROFILING}
      WEBSERVER_PROJECTS: "null"
      WEBSERVER_PUBLICATIONS: 0
      WEBSERVER_RABBITMQ: "null"
      WEBSERVER_REALTIME_COLLABORATION: "null"
      WEBSERVER_REDIS: "null"
      WEBSERVER_RESOURCE_USAGE_TRACKER: "null"
      WEBSERVER_RPC_NAMESPACE: "null"
      WEBSERVER_SCICRUNCH: "null"
      WEBSERVER_SOCKETIO: 0
      WEBSERVER_STATICWEB: "null"
      WEBSERVER_STORAGE: "null"
      WEBSERVER_STUDIES_DISPATCHER: "null"
      WEBSERVER_TAGS: 0
      WEBSERVER_TRACING: ${WB_AUTH_TRACING}
      WEBSERVER_USERS: "null"
    networks:
      - default

  agent:
    image: ${DOCKER_REGISTRY:-itisfoundation}/agent:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    deploy:
      mode: global
      resources:
        limits:
          cpus: "1.0"
          memory: 1024M

    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      <<:
        - *common_logging_environments
        - *rabbit_settings
        - *tracing_open_telemetry_environments

      AGENT_LOGLEVEL: ${AGENT_LOGLEVEL}
      AGENT_VOLUMES_CLEANUP_S3_ENDPOINT: ${AGENT_VOLUMES_CLEANUP_S3_ENDPOINT}
      AGENT_VOLUMES_CLEANUP_S3_REGION: ${AGENT_VOLUMES_CLEANUP_S3_REGION}
      AGENT_VOLUMES_CLEANUP_S3_ACCESS_KEY: ${AGENT_VOLUMES_CLEANUP_S3_ACCESS_KEY}
      AGENT_VOLUMES_CLEANUP_S3_SECRET_KEY: ${AGENT_VOLUMES_CLEANUP_S3_SECRET_KEY}
      AGENT_VOLUMES_CLEANUP_S3_BUCKET: ${AGENT_VOLUMES_CLEANUP_S3_BUCKET}
      AGENT_VOLUMES_CLEANUP_S3_PROVIDER: ${AGENT_VOLUMES_CLEANUP_S3_PROVIDER}
      AGENT_DOCKER_NODE_ID: "{{.Node.ID}}"
      AGENT_TRACING: ${AGENT_TRACING}

  notifications:
    image: ${DOCKER_REGISTRY:-itisfoundation}/notifications:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"

    environment:
      <<:
        - *common_logging_environments
        - *postgres_settings
        - *rabbit_settings
        - *tracing_open_telemetry_environments

      NOTIFICATIONS_LOGLEVEL: ${NOTIFICATIONS_LOGLEVEL}
      NOTIFICATIONS_TRACING: ${NOTIFICATIONS_TRACING}

  dask-sidecar:
    image: ${DOCKER_REGISTRY:-itisfoundation}/dask-sidecar:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    deploy:
      mode: global
      endpoint_mode: dnsrr
      resources:
        reservations:
          cpus: "0.10"
          memory: "100M"
    volumes:
      - computational_shared_data:${SIDECAR_COMP_SERVICES_SHARED_FOLDER:-/home/scu/computational_shared_data}
      - /var/run/docker.sock:/var/run/docker.sock
    environment: &sidecar-environment
      <<:
        - *rabbit_settings

      DASK_TLS_CA_FILE: ${DASK_TLS_CA_FILE}
      DASK_TLS_KEY: ${DASK_TLS_KEY}
      DASK_TLS_CERT: ${DASK_TLS_CERT}
      DASK_SCHEDULER_HOST: ${DASK_SCHEDULER_HOST:-dask-scheduler}
      DASK_LOG_FORMAT_LOCAL_DEV_ENABLED: ${LOG_FORMAT_LOCAL_DEV_ENABLED}
      DASK_LOG_FILTER_MAPPING: ${LOG_FILTER_MAPPING}
      DASK_SIDECAR_LOGLEVEL: ${DASK_SIDECAR_LOGLEVEL}
      SIDECAR_COMP_SERVICES_SHARED_VOLUME_NAME: ${SWARM_STACK_NAME}_computational_shared_data
      SIDECAR_COMP_SERVICES_SHARED_FOLDER: ${SIDECAR_COMP_SERVICES_SHARED_FOLDER:-/home/scu/computational_shared_data}
    networks:
      - computational_services_subnet
    secrets: *dask_tls_secrets

  dask-scheduler:
    image: ${DOCKER_REGISTRY:-itisfoundation}/dask-sidecar:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    environment:
      <<: *sidecar-environment
      DASK_START_AS_SCHEDULER: 1

    networks:
      - computational_services_subnet
    secrets: *dask_tls_secrets

  datcore-adapter:
    image: ${DOCKER_REGISTRY:-itisfoundation}/datcore-adapter:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    networks:
      - storage_subnet
    environment:
      <<:
        - *tracing_open_telemetry_environments

      DATCORE_ADAPTER_LOG_FILTER_MAPPING: ${LOG_FILTER_MAPPING}
      DATCORE_ADAPTER_LOG_FORMAT_LOCAL_DEV_ENABLED: ${LOG_FORMAT_LOCAL_DEV_ENABLED}
      DATCORE_ADAPTER_TRACING: ${DATCORE_ADAPTER_TRACING}

  storage:
    image: ${DOCKER_REGISTRY:-itisfoundation}/storage:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "sto-{{.Node.Hostname}}-{{.Task.Slot}}"
    environment: &storage_environment
      <<:
        - *common_logging_environments
        - *postgres_settings
        - *rabbit_settings
        - *redis_settings
        - *s3_settings
        - *tracing_open_telemetry_environments
      DATCORE_ADAPTER_HOST: ${DATCORE_ADAPTER_HOST:-datcore-adapter}
      STORAGE_WORKER_MODE: "false"
      STORAGE_LOGLEVEL: ${STORAGE_LOGLEVEL}
      STORAGE_MONITORING_ENABLED: 1
      STORAGE_PROFILING: ${STORAGE_PROFILING}
      STORAGE_PORT: ${STORAGE_PORT}
      STORAGE_TRACING: ${STORAGE_TRACING}
    networks: &storage_networks
      - default
      - interactive_services_subnet
      - storage_subnet

  sto-worker:
    image: ${DOCKER_REGISTRY:-itisfoundation}/storage:${DOCKER_IMAGE_TAG:-master-github-latest}
    init: true
    hostname: "sto-worker-{{.Node.Hostname}}-{{.Task.Slot}}"
    environment:
      <<: *storage_environment
      STORAGE_TRACING: "null"
      STORAGE_WORKER_NAME: "sto-worker-{{.Node.Hostname}}-{{.Task.Slot}}-{{.Task.ID}}"
      STORAGE_WORKER_MODE: "true"
      CELERY_CONCURRENCY: 100
      CELERY_POOL: threads
    networks: *storage_networks

  sto-worker-cpu-bound:
    image: ${DOCKER_REGISTRY:-itisfoundation}/storage:${DOCKER_IMAGE_TAG:-master-github-latest}
    init: true
    hostname: "sto-worker-cpu-bound-{{.Node.Hostname}}-{{.Task.Slot}}"
    environment:
      <<: *storage_environment
      STORAGE_TRACING: "null"
      STORAGE_WORKER_NAME: "sto-worker-cpu-bound-{{.Node.Hostname}}-{{.Task.Slot}}-{{.Task.ID}}"
      STORAGE_WORKER_MODE: "true"
      CELERY_CONCURRENCY: 1
      CELERY_QUEUES: cpu_bound
      CELERY_POOL: prefork
    networks: *storage_networks

  rabbit:
    image: itisfoundation/rabbitmq:4.1.2-management
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBIT_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBIT_PASSWORD}
    volumes:
      - rabbit_data:/var/lib/rabbitmq
    networks:
      - default
      - computational_services_subnet
      - interactive_services_subnet
      - autoscaling_subnet
    healthcheck:
      # see https://www.rabbitmq.com/monitoring.html#individual-checks for info about health-checks available in rabbitmq
      test: rabbitmq-diagnostics -q status
      interval: 5s
      timeout: 30s
      retries: 5
      start_period: 5s

  migration:
    image: ${DOCKER_REGISTRY:-itisfoundation}/migration:${DOCKER_IMAGE_TAG:-latest}
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    environment:
      <<: *postgres_settings
    networks:
      - default # actually needed for the postgres service only

  postgres:
    image: "postgres:14.8-alpine@sha256:150dd39ccb7ae6c7ba6130c3582c39a30bb5d3d22cb08ad0ba37001e3f829abc"
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - type: tmpfs
        target: /dev/shm
        tmpfs:
          size: 16000000000
    networks:
      - default
      - interactive_services_subnet
    healthcheck:
      test:
        [
          "CMD",
          "pg_isready",
          "--username",
          "${POSTGRES_USER}",
          "--dbname",
          "${POSTGRES_DB}",
        ]
      interval: 5s
      retries: 5
    # NOTES: this is not yet compatible with portainer deployment but could work also for other containers
    # works with Docker 19.03 and not yet with Portainer 1.23.0 (see https://github.com/portainer/portainer/issues/3551)
    # in the meantime postgres allows to set a configuration through CLI.
    # sysctls:
    #   # NOTES: these values are needed here because docker swarm kills long running idle
    #   # connections by default after 15 minutes see https://github.com/moby/moby/issues/31208
    #   # info about these values are here https://tldp.org/HOWTO/TCP-Keepalive-HOWTO/usingkeepalive.html
    #   - net.ipv4.tcp_keepalive_intvl=600
    #   - net.ipv4.tcp_keepalive_probes=9
    #   - net.ipv4.tcp_keepalive_time=600
    #
    command: [
        "postgres",
        "-c",
        "tcp_keepalives_idle=600",
        "-c",
        "tcp_keepalives_interval=600",
        "-c",
        "tcp_keepalives_count=5",
        "-c",
        "max_connections=413",
        "-c",
        "shared_buffers=256MB",
        # statement_timeout is set to 120 seconds (120_000 in ms), so that long running queries
        # are killed after 2 minutes. Since simcore services have timeout of 1 minute, so longer
        # queries will not be used. Setting >1 minutes to be safe
        # https://github.com/ITISFoundation/osparc-simcore/issues/7682#issuecomment-2923048445
        "-c",
        "statement_timeout=120000",
      ]

  redis:
    image: "redis:6.2.6@sha256:4bed291aa5efb9f0d77b76ff7d4ab71eee410962965d052552db1fb80576431d"
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    command:
      # redis server will write a backup every 60 seconds if at least 1 key was changed
      # also aof (append only) is also enabled such that we get full durability at the expense
      # of backup size. The backup is written into /data.
      # https://redis.io/topics/persistence
      [
        "redis-server",
        "--save",
        "60 1",
        "--loglevel",
        "verbose",
        "--databases",
        "11",
        "--appendonly",
        "yes",
        "--requirepass",
        "${REDIS_PASSWORD}",
      ]
    networks:
      - default
      - autoscaling_subnet
      - interactive_services_subnet
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 5s
      timeout: 30s
      retries: 50

  traefik:
    image: "traefik:v3.5.2@sha256:07ff0c6c2114233b82e1de8e9f4fee9974470cd8d42c22e4e158538d950e19ae"
    init: true
    hostname: "{{.Node.Hostname}}-{{.Task.Slot}}"
    command:
      - "--api=true"
      - "--api.dashboard=true"
      - "--ping=true"
      - "--entryPoints.ping.address=:9082"
      - "--ping.entryPoint=ping"
      - "--log.level=WARN" # WARN, not WARNING
      - "--accesslog=false"
      - "--metrics.prometheus=true"
      - "--metrics.prometheus.addEntryPointsLabels=true"
      - "--metrics.prometheus.addServicesLabels=true"
      - "--entryPoints.metrics.address=:8082"
      - "--metrics.prometheus.entryPoint=metrics"
      - "--entryPoints.http.address=:80"
      - "--entryPoints.http.forwardedHeaders.insecure"
      - "--entryPoints.http.transport.respondingTimeouts.readTimeout=21600s" #6h, for https://github.com/traefik/traefik/issues/10805 large file uploads
      - "--entryPoints.http.transport.respondingTimeouts.writeTimeout=21600s" #6h, for https://github.com/traefik/traefik/issues/10805 large file downloads
      - "--entryPoints.simcore_api.address=:10081"
      - "--entryPoints.simcore_api.forwardedHeaders.insecure"
      - "--entryPoints.simcore_api.transport.respondingTimeouts.readTimeout=21600s" #6h, for https://github.com/traefik/traefik/issues/10805 large file uploads
      - "--entryPoints.simcore_api.transport.respondingTimeouts.writeTimeout=21600s" #6h, for https://github.com/traefik/traefik/issues/10805 large file downloads
      - "--entryPoints.traefik_monitor.address=:8080"
      - "--entryPoints.traefik_monitor.forwardedHeaders.insecure"
      - "--providers.swarm.endpoint=unix:///var/run/docker.sock"
      - "--providers.swarm.network=${SWARM_STACK_NAME}_default"
      # https://github.com/traefik/traefik/issues/7886
      - "--providers.swarm.refreshSeconds=1"
      - "--providers.swarm.exposedByDefault=false"
      - "--providers.swarm.constraints=Label(`io.simcore.zone`, `${TRAEFIK_SIMCORE_ZONE}`)"
      - "--tracing"
      - "--tracing.addinternals"
      - "--tracing.otlp=true"
      - "--tracing.otlp.http=true"
      - "--tracing.sampleRate=${TRACING_OPENTELEMETRY_SAMPLING_PROBABILITY}"
    healthcheck:
      # NOTE: this healthcheck to check if traefik is up and running must be run on the ping entrypoint defined in command!
      test: traefik healthcheck --ping --ping.entryPoint=ping --entryPoints.ping.address=:9082
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
      start_interval: 1s
    volumes:
      # So that Traefik can listen to the Docker events
      - /var/run/docker.sock:/var/run/docker.sock
    deploy:
      placement:
        constraints:
          - node.role == manager
      labels:
        # for each service in the stack a new middlaware for rate limiting needs to be registered here
        # requests = average / period this is how the limits are defined
        - traefik.http.middlewares.ratelimit-${SWARM_STACK_NAME}_api-server.ratelimit.average=1
        - traefik.http.middlewares.ratelimit-${SWARM_STACK_NAME}_api-server.ratelimit.period=1m
        # a burst is computed over a period of 1 second
        - traefik.http.middlewares.ratelimit-${SWARM_STACK_NAME}_api-server.ratelimit.burst=10
        # X-Forwarded-For header extracts second IP from the right, count starts at one
        - traefik.http.middlewares.ratelimit-${SWARM_STACK_NAME}_api-server.ratelimit.sourcecriterion.ipstrategy.depth=2
        # middleware for limiting total inflight requests the api-server is handling
        - traefik.http.middlewares.ensure-group-header-${SWARM_STACK_NAME}_api-server.headers.customrequestheaders.X-Inflight-Limit-Group=all
        - traefik.http.middlewares.limit-reqs-${SWARM_STACK_NAME}_api-server.inflightreq.amount=${TRAEFIK_API_SERVER_INFLIGHTREQ_AMOUNT}
        - traefik.http.middlewares.limit-reqs-${SWARM_STACK_NAME}_api-server.inflightreq.sourcecriterion.requestheadername=X-Inflight-Limit-Group
        - traefik.http.middlewares.inflightreq-${SWARM_STACK_NAME}_api-server.chain.middlewares=ensure-group-header-${SWARM_STACK_NAME}_api-server,limit-reqs-${SWARM_STACK_NAME}_api-server
    networks:
      - default
      - interactive_services_subnet # for legacy dynamic services

  # use to define fallback routes for simcore services
  # if docker healthcheck fails, container's traefik configuration is removed
  # leading to 404 https://github.com/traefik/traefik/issues/7842
  #
  # use fallback routes to return proper 503 (instead of 404)
  # this service must be running at all times
  traefik-config-placeholder:
    image: busybox:1.35.0
    command: sleep infinity
    networks:
      - default
    deploy:
      labels:
        # route to internal traefik
        - traefik.enable=true
        - io.simcore.zone=${TRAEFIK_SIMCORE_ZONE}

        ### Fallback for api-server
        - traefik.http.routers.${SWARM_STACK_NAME}_api-server_fallback.rule=(Path(`/`) || Path(`/v0`) ||  PathPrefix(`/v0/`) || Path(`/api/v0/openapi.json`))
        - traefik.http.routers.${SWARM_STACK_NAME}_api-server_fallback.service=${SWARM_STACK_NAME}_api-server_fallback
        - traefik.http.routers.${SWARM_STACK_NAME}_api-server_fallback.entrypoints=simcore_api
        - traefik.http.routers.${SWARM_STACK_NAME}_api-server_fallback.priority=1
        # always fail and return 503 via unhealthy loadbalancer healthcheck
        - traefik.http.services.${SWARM_STACK_NAME}_api-server_fallback.loadbalancer.server.port=0 # port is required (otherwise traefik service is not created)
        - traefik.http.services.${SWARM_STACK_NAME}_api-server_fallback.loadbalancer.healthcheck.path=/some/invalid/path/to/generate/a/503
        - traefik.http.services.${SWARM_STACK_NAME}_api-server_fallback.loadbalancer.healthcheck.interval=10s
        - traefik.http.services.${SWARM_STACK_NAME}_api-server_fallback.loadbalancer.healthcheck.timeout=1ms

        ### Fallback for webserver
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_fallback.service=${SWARM_STACK_NAME}_webserver_fallback
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_fallback.rule=(Path(`/`) || Path(`/v0`) || Path(`/socket.io/`) || Path(`/static-frontend-data.json`) || PathRegexp(`^/study/(?P<study_uuid>\b[0-9a-f]{8}\b-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-\b[0-9a-f]{12}\b)`) || Path(`/view`) || Path(`/#/view`) || Path(`/#/error`) || PathPrefix(`/v0/`))
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_fallback.entrypoints=http
        - traefik.http.routers.${SWARM_STACK_NAME}_webserver_fallback.priority=1
        # always fail and return 503 via unhealthy loadbalancer healthcheck
        - traefik.http.services.${SWARM_STACK_NAME}_webserver_fallback.loadbalancer.server.port=0
        - traefik.http.services.${SWARM_STACK_NAME}_webserver_fallback.loadbalancer.healthcheck.path=/v0/
        - traefik.http.services.${SWARM_STACK_NAME}_webserver_fallback.loadbalancer.healthcheck.interval=10s
        - traefik.http.services.${SWARM_STACK_NAME}_webserver_fallback.loadbalancer.healthcheck.timeout=1ms

        ### Fallback for static-webserver
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver_fallback.rule=(Path(`/osparc`) || Path(`/s4l`) || Path(`/s4llite`) || Path(`/s4lacad`) || Path(`/s4lengine`) || Path(`/s4ldesktop`) || Path(`/s4ldesktopacad`) || Path(`/tis`) || Path(`/tiplite`) || Path(`/transpiled`) || Path(`/resource`) || PathPrefix(`/osparc/`) || PathPrefix(`/s4l/`) || PathPrefix(`/s4llite/`) || PathPrefix(`/s4lacad/`) || PathPrefix(`/s4lengine/`) || PathPrefix(`/s4ldesktop/`) || PathPrefix(`/s4ldesktopacad/`) || PathPrefix(`/tis/`) || PathPrefix(`/tiplite/`) || PathPrefix(`/transpiled/`) || PathPrefix(`/resource/`))
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver_fallback.service=${SWARM_STACK_NAME}_static_webserver_fallback
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver_fallback.entrypoints=http
        - traefik.http.routers.${SWARM_STACK_NAME}_static_webserver_fallback.priority=1
        # always fail and return 503 via unhealthy loadbalancer healthcheck
        - traefik.http.services.${SWARM_STACK_NAME}_static_webserver_fallback.loadbalancer.server.port=0
        - traefik.http.services.${SWARM_STACK_NAME}_static_webserver_fallback.loadbalancer.healthcheck.path=/some/invalid/path/to/generate/a/503
        - traefik.http.services.${SWARM_STACK_NAME}_static_webserver_fallback.loadbalancer.healthcheck.interval=10s
        - traefik.http.services.${SWARM_STACK_NAME}_static_webserver_fallback.loadbalancer.healthcheck.timeout=1ms
    healthcheck:
      test: command -v sleep
      interval: 10s
      timeout: 1s
      start_period: 1s
      retries: 3

volumes:
  postgres_data:
    name: ${SWARM_STACK_NAME}_postgres_data
  computational_shared_data:
    name: ${SWARM_STACK_NAME}_computational_shared_data
  redis-data:
    name: ${SWARM_STACK_NAME}_redis-data
  rabbit_data:
    name: ${SWARM_STACK_NAME}_rabbit_data

networks:
  default:
    attachable: true
    name: ${SWARM_STACK_NAME}_default
  storage_subnet:
    attachable: true
    name: ${SWARM_STACK_NAME}_storage_subnet
  autoscaling_subnet:
    attachable: true
    name: ${SWARM_STACK_NAME}_autoscaling_subnet
  interactive_services_subnet:
    name: ${SWARM_STACK_NAME}_interactive_services_subnet
    driver: overlay
    attachable: true
    internal: false
    labels:
      com.simcore.description: "interactive services network"
  computational_services_subnet:
    name: ${SWARM_STACK_NAME}_computational_services_subnet
    driver: overlay
    attachable: true
    internal: false
    labels:
      com.simcore.description: "computational services network"
  docker_api_subnet:
    name: ${SWARM_STACK_NAME}_docker_api_subnet
    driver: overlay
    attachable: true
    internal: true
    driver_opts:
      encrypted: "true"
    labels:
      com.simcore.description: "used for internal access to the docker swarm api"

secrets:
  dask_tls_key:
    file: ./dask-sidecar/.dask-certificates/dask-key.pem
    name: ${SWARM_STACK_NAME}_dask_tls_key
  dask_tls_cert:
    file: ./dask-sidecar/.dask-certificates/dask-cert.pem
    name: ${SWARM_STACK_NAME}_dask_tls_cert
